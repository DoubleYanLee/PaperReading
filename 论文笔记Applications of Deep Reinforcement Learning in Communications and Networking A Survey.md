# Applications of Deep Reinforcement Learning in Communications and Networking: A Survey

## NETWORK ACCESS AND RATE CONTROL

â€‹		ç‰©è”ç½‘ç­‰ç°ä»£ç½‘ç»œåœ¨æœ¬è´¨ä¸Šå˜å¾—æ›´åŠ å»ä¸­å¿ƒåŒ–å’Œad-hocã€‚åœ¨è¿™æ ·çš„ç½‘ç»œä¸­ï¼Œä¼ æ„Ÿå™¨å’Œç§»åŠ¨ç”¨æˆ·ç­‰å®ä½“éœ€è¦åšå‡ºç‹¬ç«‹çš„å†³ç­–ï¼Œä¿¡é“å’ŒåŸºç«™çš„é€‰æ‹©ï¼Œä»¥å®ç°è‡ªå·±çš„ç›®æ ‡ï¼Œå¦‚ååé‡æœ€å¤§åŒ–ã€‚

â€‹		ä½†ç½‘ç»œçŠ¶æ€å…·æœ‰åŠ¨æ€æ€§å’Œä¸ç¡®å®šæ€§ã€‚

* *Dynamic spectrum access:* åŠ¨æ€é¢‘è°±è®¿é—®å…è®¸ç”¨æˆ·åœ¨æœ¬åœ°é€‰æ‹©ä¿¡é“ï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜å…¶ååé‡ã€‚ä½†ç”¨æˆ·å¯èƒ½æ²¡æœ‰å¯¹ç³»ç»Ÿçš„å®Œæ•´è§‚å¯Ÿï¼Œso use DQL
* *Joint user association and spectrum access:*  User association is implemented to determine which user to be assigned to which Base Station.  (joint user association and spectrum access problems in[42][43]) è¿™æ˜¯ä¸ªéå‡¸ä¼˜åŒ–ç»„åˆé—®é¢˜ï¼Œso use DQLï¼ˆæä¾›åˆ†å¸ƒå¼çš„è§£å†³æ–¹æ¡ˆï¼‰

> å‡¸å‡½æ•°çš„å±€éƒ¨æœ€ä¼˜è§£å°±æ˜¯å…¨å±€æœ€ä¼˜è§£ï¼Œåœ¨æ•°å­¦ä¸­çš„ä¸€ä¸ªéå‡¸çš„æœ€ä¼˜åŒ–é—®é¢˜ä¹Ÿå°±æ„å‘³ç€å±€éƒ¨æœ€ä¼˜è§£å¹¶ä¸æ˜¯å…¨å±€æœ€ä¼˜è§£,æ‰€ä»¥éå‡¸å‡½æ•°çš„å¯»ä¼˜æ˜¯æœ€éš¾çš„  
>
> å› ä¸ºéå‡¸ï¼Œæ‰€ä»¥è¦å¯¹å…¨å±€éƒ½è¦æœ‰ä¸€ä¸ªäº†è§£ ã€‚å³éœ€è¦æ¥è¿‘å®Œå…¨å’Œå‡†ç¡®çš„ç½‘ç»œä¿¡æ¯æ¥è·å¾—æœ€ä¼˜ç­–ç•¥

* *Adaptive rate control:*  HTTPä¸Šçš„åŠ¨æ€è‡ªé€‚åº”æµ(DASH)ç³»ç»Ÿï¼Œå…¶å…è®¸å®¢æˆ·ç«¯æˆ–ç”¨æˆ·ç‹¬ç«‹é€‰æ‹©ä¸åŒæ¯”ç‰¹ç‡çš„è§†é¢‘ç‰‡æ®µä¸‹è½½ã€‚ç›®æ ‡å°±æ˜¯æœ€å¤§åŒ–å…¶ä½“éªŒè´¨é‡(QoE)ã€‚so use DQL

>ä¸ç”¨åŠ¨æ€è§„åˆ’çš„åŸå› ï¼šåŠ¨æ€è§„åˆ’çš„å¤æ‚æ€§é«˜ï¼Œä¸”éœ€è¦å®Œæ•´çš„ç½‘ç»œä¿¡æ¯ã€‚

### *Network Access* ç½‘ç»œæ¥å…¥(spectrum access & user association)

>i.e. æ‹‰ä¸è¯­çš„id est  æ„ä¸º"that is"å³   e.g. æ‹‰ä¸è¯­çš„exempligratia ä¸¾ä¾‹

#### channel access

* ä¼ æ„Ÿå™¨é€‰æ‹©Mæ¡é€šé“æ¥ä¼ è¾“ç½‘ç»œåŒ…ï¼Œæ ¹æ®ä¼ è¾“åçš„åé¦ˆï¼Œå¥½é“¾è·¯ reward "+1â€œ  ä¸å¥½çš„é“¾è·¯ reward"-1". 

  * ç›®çš„ï¼šæ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„ç­–ç•¥æ¥æœ€å¤§åŒ–sensorâ€™s expected accumulated discounted reward

  * ç‰©ä½“ä¹‹å‰æ˜¯é€‰æ‹©çŸ­è§†(myopic)ç­–ç•¥è¿™ä¸ªæ–¹æ¡ˆ  ä½†myopicç­–ç•¥éœ€è¦çŸ¥é“system transition matrix
  * ç°åœ¨ç”¨ DQN çš„ç»éªŒé‡æ”¾(experience replay)ç­–ç•¥  
  * DQN è¾“å…¥state(action & reward)  è¾“å‡ºQ-values(actionç›¸å…³çš„Q-values)   adopt  Îµ-greedy policy
  * ç»“æœï¼šè¯¥æ–¹æ¡ˆçš„å¹³å‡å¥–åŠ±å€¼ä¸º4.4ï¼Œ æ¥è¿‘äºmyopicç­–ç•¥çš„4.5ã€‚

DQL keeps following the learned policy over time slots and stops learning a suitable policy. But IoT environments are dynamic,  the DQN in the DQL needs to be re-trained

* adaptive DQL scheme is proposed  è¯¥æ–¹æ¡ˆè¯„ä¼°å½“å‰ç­–ç•¥æ¯ä¸€æ—¶æœŸçš„ç´¯ç§¯å¥–åŠ±ï¼Œå½“rewardä½äºç»™å®šçš„é˜€å€¼æ—¶ï¼ŒDQNä¼šè¢«é‡æ–°è®­ç»ƒå»æ‰¾åˆ°ä¸€ä¸ªnew good policyã€‚

#### ä¸Šé¢çš„éƒ½æ˜¯one sensorï¼Œç°åœ¨è€ƒè™‘multi-sensorçš„åœºæ™¯

> joint channel selection and packet forwarding  è”åˆé€šé“é€‰æ‹©å’ŒåŒ…è½¬å‘

![Screenshot 2021-01-05 at 2.25.14 PM](/Users/yannie/Library/Application Support/typora-user-images/Screenshot 2021-01-05 at 2.25.14 PM.png)ä¸€ä¸ªä¼ æ„Ÿå™¨ä½œä¸ºä¸­ç»§(relay)ï¼Œå°†ä»ç›¸é‚»ä¼ æ„Ÿå™¨æ¥æ”¶åˆ°çš„æ•°æ®åŒ…è½¬å‘åˆ°æ¥æ”¶å™¨(sink)ã€‚Relayï¼ˆä¸­ç»§èŠ‚ç‚¹ï¼‰æœ‰ä¸€ä¸ªbufferï¼Œæ¥å­˜å‚¨æ¥æ”¶åˆ°çš„æ•°æ®åŒ…ã€‚åœ¨æ¯ä¸ªæ—¶é—´åºåˆ—ä¸­ï¼Œè¿™ä¸ªsensoré€‰æ‹©ä¸€ç»„é€šé“(èƒ½æœ€å¤§åŒ– (å‘é€æ•°æ®åŒ…çš„æ•°é‡ : å‘é€åŠŸç‡) )æ¥è½¬å‘æ•°æ®åŒ…ã€‚

* the sensorâ€™s problem can be formulated as an MDP
  * action: é€‰æ‹©ä¸€ç»„é€šé“  é€šé“ä¸Šä¼ è¾“çš„æ•°æ®åŒ…æ•°é‡  å’Œ è°ƒåˆ¶æ¨¡å¼
  * stateï¼š ç»“åˆbuffer state å’Œ channel state
  * è¾“å…¥æ˜¯ state  è¾“å‡ºæ˜¯è¦é€‰æ‹©çš„action
  * ä¼ æ„Ÿå™¨çš„æ•ˆç”¨å‡½æ•°æ˜¯æœ‰ç•Œçš„ï¼Œæ‰€ä»¥ç®—æ³•è¢«è¯æ˜æ˜¯æ”¶æ•›çš„ã€‚
  * ç»“æœï¼šä¸random action selection schemeç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆæ˜¾è‘—æé«˜äº†ç³»ç»Ÿçš„æ•ˆç”¨ã€‚
  * ä¸è¶³ï¼šéšç€æ•°æ®åŒ…åˆ°è¾¾ç‡çš„å¢åŠ ï¼Œç”±äºä¼ æ„Ÿå™¨éœ€è¦æ¶ˆè€—æ›´å¤šçš„åŠŸç‡æ¥ä¼ è¾“æ‰€æœ‰æ•°æ®åŒ…ï¼Œå› æ­¤è¯¥æ–¹æ¡ˆçš„ç³»ç»Ÿæ•ˆç”¨ä¼šé™ä½ã€‚

#### The channel access problem in the energy harvesting-enabled IoT system

![Screenshot 2021-01-05 at 3.59.56 PM](/Users/yannie/Library/Application Support/typora-user-images/Screenshot 2021-01-05 at 3.59.56 PM.png)

	* BSä½œä¸ºæ§åˆ¶å™¨ä¸ºä¼ æ„Ÿå™¨åˆ†é…ä¿¡é“ã€‚
	* ç„¶è€Œï¼Œç”±äºä¼ æ„Ÿå™¨èƒ½é‡å¯ç”¨æ€§çš„ä¸ç¡®å®šæ€§ï¼Œå°±å¯èƒ½ä½¿ä¿¡é“åˆ†é…æ•ˆç‡ä½ä¸‹ã€‚æ¯”å¦‚ï¼šç»™é‚£äº›èƒ½é‡ä¸å¤šçš„ä¼ æ„Ÿå™¨åˆ†é…ä¿¡é“æ˜¯ä¸åˆ’ç®—çš„ï¼Œå› ä¸ºä»–ä»¬å¾ˆå¿«å°±ä¸èƒ½ç”¨äº†

* BSçš„é—®é¢˜æ˜¯ï¼šé¢„æµ‹ä¼ æ„Ÿå™¨çš„ğŸ”‹çŠ¶æ€ï¼Œå¹¶ä¸ºchannel accessé€‰æ‹©ä¼ æ„Ÿå™¨ï¼Œä»¥ä½¿total rateæœ€å¤§åŒ–

  	* è¿‡å»ï¼šä½¿ç”¨ä¸Šè¡Œèµ„æºåˆ†é…æ–¹æ¡ˆ    ç¼ºç‚¹ï¼šè¯¥æ–¹æ¡ˆè¦æ±‚BSå¯¹æ‰€æœ‰éšæœºè¿‡ç¨‹éƒ½æœ‰ perfect non-causal knowledgeã€‚
  	* ä½†æ˜¯ä¼ æ„Ÿå™¨éšæœºåˆ†å¸ƒåœ¨ä¸€ä¸ªåœ°ç†åŒºåŸŸå†…ï¼Œæ‰€ä»¥å¯èƒ½æ— æ³•è·å¾— perfect non-causal knowledgeã€‚ so use DQL
  	* DQLä½¿ç”¨ç”±ä¸¤ä¸ªåŸºäºLSTMçš„ç¥ç»ç½‘ç»œå±‚ç»„æˆçš„DQNã€‚ç¬¬ä¸€å±‚æ¥é¢„æµ‹ä¼ æ„Ÿå™¨çš„ç”µæ± çŠ¶æ€ï¼Œç¬¬äºŒå±‚åˆ©ç”¨é¢„æµ‹çš„çŠ¶æ€å’Œé€šé“çŠ¶æ€ä¿¡æ¯(CSI)æ¥ç¡®å®šé€šé“è®¿é—®ç­–ç•¥ã€‚
  	* stateé›†åˆåŒ…æ‹¬ï¼š(1)é€šé“è®¿é—®çš„åˆ†é…å†å²;  (2) é¢„æµ‹çš„ç”µé‡ä¿¡æ¯å†å²;  (3)çœŸå®çš„ç”µé‡ä¿¡æ¯å†å²;(4)ä¼ æ„Ÿå™¨å½“å‰(Channel State Information)CSIã€‚
  	* actioné›†åˆåŒ…å«ï¼šè¢«é€‰æ‹©è¿‡çš„ä¼ æ„Ÿå™¨é›†åˆ
  	* rewardæ˜¯ï¼šæ€»é€Ÿç‡å’Œé¢„æµ‹è¯¯å·®ä¹‹é—´çš„å·®å€¼ã€‚
  	* ç»“æœï¼šè¯¥æ–¹æ¡ˆåœ¨æ€»é€Ÿç‡ä¸Šæ¥è¿‘æœ€ä¼˜æ–¹æ³•[52]ï¼Œä¼˜äºmyopicç­–ç•¥[45]ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆè·å¾—çš„ç”µæ± ç”µé‡é¢„æµ‹è¯¯å·®æ¥è¿‘äºé›¶ã€‚

  #### ä»¥ä¸Šçš„æ–¹æ³•éƒ½å…³æ³¨ä¼˜åŒ–rate maximization ä½†åœ¨V2Vç³»ç»Ÿä¸­ï¼Œå»¶è¿Ÿä¹Ÿè¦è€ƒè™‘

  * æ¯ä¸ªV2V transmitter/receiveré¢ä¸´çš„é—®é¢˜ï¼šåœ¨çº¦æŸå»¶è¿Ÿæ—¶é—´çš„æƒ…å†µä¸‹é€‰æ‹©ä¿¡é“å’Œå‘å°„åŠŸç‡ï¼Œä½¿å…¶å®¹é‡æœ€å¤§åŒ–ã€‚
  * DQNä¸­each V2V transmitterçš„actionï¼šé€‰æ‹©ä¿¡é“å’Œé€‰æ‹©å‘é€åŠŸç‡
  * rewardæ˜¯ï¼šæœ‰å…³V2V transmitterå®¹é‡å’Œå»¶è¿Ÿçš„å‡½æ•°
  * stateåŒ…æ‹¬ï¼š(1)å¯¹åº”V2Vé“¾è·¯çš„ç¬æ—¶CSI  (2)å‰ä¸€ä¸ªæ—¶éš™ä¸­ V2Vé“¾è·¯çš„å¹²æ‰°  (3)åœ¨å‰ä¸€æ—¶é—´æ®µå†…ï¼ŒV2Vå‘å°„æœºçš„é‚»å±…æ‰€é€‰æ‹©çš„ä¿¡é“  (4)æ»¡è¶³å»¶è¿Ÿçº¦æŸçš„å‰©ä½™æ—¶é—´ã€‚
  * è¾“å…¥ï¼šstate  action    è¾“å‡ºï¼šè¯¥actionæ‰€å¾—åˆ°çš„Q-values
  * ç»“æœï¼šåœ¨è½¦è¾†é“¾è·¯æœ‰å¯èƒ½è¿åå»¶è¿Ÿçº¦æŸæ—¶ï¼Œæ¥åŠ¨æ€è°ƒæ•´åŠŸç‡å’Œä¿¡é“é€‰æ‹©ã€‚è¯¥æ–¹æ¡ˆå¯¹æ¯”éšæœºä¿¡é“åˆ†é…æ–¹æ¡ˆï¼Œæ»¡è¶³å»¶è¿Ÿçº¦æŸçš„è½¦è¾†å‘å°„æœºæ•°é‡æ›´å¤šäº†ã€‚

  

  ä¸ºäº†é™ä½é¢‘è°±æˆæœ¬ï¼Œä¸Šè¿°loTç³»ç»Ÿé€šå¸¸ä½¿ç”¨æœªæˆæƒ(unlicensed)çš„ä¿¡é“ã€‚ä½†è¿™å¯èƒ½å¯¹ç°æœ‰çš„ç½‘ç»œäº§ç”Ÿå¹²æ‰°ã€‚

  >ä»€ä¹ˆå« unlicensed channelï¼Ÿ

  ####  (è¿™ä¸ªåº”ç”¨ä¸å¤ªæ‡‚)åˆ©ç”¨DQNå°†åŠ¨æ€ä¿¡é“æ¥å…¥å’Œå¹²æ‰°ç®¡ç†é—®é¢˜ä¸€èµ·éƒ½è§£å†³ï¼š

  ![Screenshot 2021-01-05 at 5.53.46 PM](/Users/yannie/Library/Application Support/typora-user-images/Screenshot 2021-01-05 at 5.53.46 PM.png)

  > SBS(Small Base Station).  LTE network: Long-Term Evolution(ä¸€ä¸ªæ ‡å‡†) network

  åœ¨æ¯ä¸ªæ—¶éš™ï¼ŒSBSé€‰æ‹©ä¸€ä¸ªé€šé“æ¥ä¼ è¾“å…¶æ•°æ®åŒ…ã€‚ä½†æ˜¯ï¼Œæ‰€é€‰é€šé“ä¸Šå¯èƒ½æœ‰WLANé€šä¿¡ï¼Œå› æ­¤SBSæ¦‚ç‡æ€§åœ°è®¿é—®æ‰€é€‰é€šé“ã€‚

  * SBSçš„actionï¼šä¿¡é“é€‰æ‹©å’Œæ¦‚ç‡æ€§åœ°è®¿é—®ä¿¡é“
  * SBSçš„é—®é¢˜æ˜¯ï¼šç¡®å®šä¸€ä¸ªaction vectorï¼Œä»¥ä¾¿åœ¨æ‰€æœ‰é€šé“å’Œæ—¶é—´æ®µå†…æœ€å¤§é™åº¦åœ°æé«˜å…¶æ€»ååé‡ï¼Œå³æœ€å¤§åŒ–æ•ˆç”¨å‡½æ•°ã€‚ 
  * **ï¼ˆè¿™é‡Œä¸ºä»€ä¹ˆåˆè°ˆåŠèµ„æºåˆ†é…ï¼‰**èµ„æºåˆ†é…é—®é¢˜å¯ä»¥è¡¨è¿°ä¸ºä¸€ä¸ªéåˆä½œåšå¼ˆï¼ˆnon-cooperative gameï¼‰ï¼Œåˆ©ç”¨åŸºäºLSTMçš„DQNå¯ä»¥æ±‚è§£è¯¥åšå¼ˆã€‚
  * DQNè¾“å…¥ï¼šè¯¥é€šé“ä¸ŠSBSså’ŒWLANçš„å†å²æµé‡    è¾“å‡ºï¼š SBSsçš„é¢„æµ‹action vector

  The utility function of each SBS is proved to be convex, and thus the DQN-based algorithm converges to a Nash equilibrium of the game. 

  >è¯æ˜äº†æ¯ä¸ªSBSçš„æ•ˆç”¨å‡½æ•°æ˜¯å‡¸çš„ï¼Œå› æ­¤åŸºäºDQNçš„ç®—æ³•æ”¶æ•›äºåšå¼ˆçš„çº³ä»€å‡è¡¡ã€‚

  * ç»“æœï¼šä¸æ ‡å‡†Q-learningç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆçš„å¹³å‡ååé‡æé«˜äº†28%ã€‚

  ##### (è¿™ä¸ªä¹Ÿä¸æ˜¯å¾ˆæ‡‚)å¤šç”¨æˆ·å…±äº«Kä¸ªä¿¡é“çš„åŠ¨æ€é¢‘è°±è®¿é—®é—®é¢˜

  åœ¨æŸä¸ªæ—¶éš™ï¼Œç”¨æˆ·ä»¥ä¸€å®šçš„å°è¯•æ¦‚ç‡é€‰æ‹©ä¿¡é“æˆ–é€‰æ‹©æ ¹æœ¬ä¸ä¼ è¾“æ•°æ®åŒ…ã€‚

  1)  state: ç”¨æˆ·å†å²çš„actionå’Œå½“å‰çš„obeservation

  2)  ç”¨æˆ·çš„ç­–ç•¥æ˜¯: mapping from the history to an attempt probability. 

  3) é—®é¢˜ï¼šæ‰¾åˆ°ä¸€ä¸ªç­–ç•¥å‘é‡ï¼Œä¹Ÿå°±æ˜¯policy, ä»è€Œmaximize its expected accumulated discounted data rate of the user

  ä»¥ä¸Šçš„é—®é¢˜è®­ç»ƒä¸€ä¸ªDQNæ¥è§£å†³

  * è¾“å…¥ï¼špast actions å’Œ the corresponding observations.    è¾“å‡ºï¼šestimated Q-values of the actions
  * ä¸ºäº†é¿å…Q-learningçš„è¿‡é«˜ä¼°è®¡ï¼Œæˆ‘ä»¬ä½¿ç”¨DDQNæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

  the multichannel random access is modeled as a non-cooperative game, the game has a subgame perfect equilibrium.

  Note that some users can keep increasing their attempt probability to increase their rates. This makes the equilibrium point inefficient, and thus the strategy space of the users is restricted to avoid the situation.

  ç”¨æˆ·çš„è¿™ç§ç­–ç•¥ç©ºé—´(ä¸æ–­å¢åŠ å°è¯•çš„å¯èƒ½æ€§ï¼Œä»¥æé«˜å…¶æˆåŠŸç‡)æ˜¯è¢«é™åˆ¶çš„

  * ç»“æœï¼šè¯¥æ–¹æ¡ˆçš„ä¿¡é“ååé‡æ˜¯slotted-Aloha [56]çš„ä¸¤å€ã€‚åŸå› æ˜¯ï¼Œåœ¨è¯¥æ–¹æ¡ˆä¸­ï¼Œæ¯ä¸ªç”¨æˆ·ä»…ä»å…¶å±€éƒ¨è§‚å¯Ÿä¸­å­¦ä¹ ï¼Œæ²¡æœ‰åœ¨çº¿åè°ƒæˆ–è½½æ³¢æ„ŸçŸ¥

  

  **åœ¨ä¸Šè¿°æ¨¡å‹ä¸­ï¼Œç”¨æˆ·æ•°é‡åœ¨æ‰€æœ‰æ—¶é—´æ®µéƒ½æ˜¯å›ºå®šçš„ï¼Œä¸è€ƒè™‘æ–°ç”¨æˆ·çš„åˆ°æ¥ã€‚**

  è¯¥ç³»ç»Ÿçš„é—®é¢˜æ˜¯æ‰¾åˆ°ä¸€ç§ä¿¡é“åˆ†é…å†³ç­–ï¼Œä½¿æ–°UT(User Terminals)åœ¨æ—¶é—´æ®µå†…çš„æ€»æœåŠ¡é˜»å¡æ¦‚ç‡æœ€å°ï¼ŒåŒæ—¶åˆä¸ä¼šå¯¹å½“å‰UTé€ æˆå¹²æ‰°ã€‚

  The systemâ€™s problem can be viewed as a temporal correlated sequential decision-making optimization problem.

  * Agent: satellite system
  * Actionï¼š is an index indicating which channel is allocated to the new arrived UT.
  * stateé›†åˆ:  current UTs, the current channel allocation matrix, and the new arrived UT.(ç”±äºåŒä¿¡é“å¹²æ‰°ï¼ŒçŠ¶æ€å…·æœ‰ç©ºé—´ç›¸å…³ç‰¹å¾,æ‰€ä»¥å¯ä»¥ç”¨image tensoræ¥è¡¨ç¤ºã€‚å› æ­¤ï¼ŒDQNé‡‡ç”¨CNNæ¥æå–çŠ¶æ€çš„æœ‰ç”¨ç‰¹å¾)
  * reward: is positive when the new service is satisfied and is negative when the service is blocked
  * ç»“æœï¼šé€šè¿‡å°†å¯ç”¨ä¿¡é“åˆ†é…ç»™æ–°åˆ°è¾¾çš„UTsï¼Œä¸å›ºå®šä¿¡é“åˆ†é…æ–¹æ¡ˆç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆå¯ä»¥å°†ç³»ç»Ÿæµé‡æé«˜24.4%ã€‚
  * ä¸è¶³ï¼šéšç€UTsæ•°ç›®çš„å¢åŠ ï¼Œå¯ç”¨é€šé“æ•°ç›®å¾ˆä½ï¼Œç”šè‡³ä¸ºé›¶ã€‚æ­¤æ—¶ï¼Œæ‰€ææ–¹æ¡ˆçš„åŠ¨æ€ä¿¡é“åˆ†é…å†³ç­–å˜å¾—æ¯«æ— æ„ä¹‰ï¼Œä¸¤ç§æ–¹æ¡ˆä¹‹é—´çš„æ€§èƒ½å·®å¼‚å˜å¾—ä¸æ˜¾è‘—ã€‚åœ¨æœªæ¥çš„å·¥ä½œä¸­ï¼Œå¯ä»¥ç ”ç©¶ä¸€ç§åŸºäºDQLçš„ä¿¡é“å’ŒåŠŸç‡è”åˆåˆ†é…ç®—æ³•ã€‚(a joint channel and power allocation algorithm based on the DQL can be investigated.)

  ### *Joint User Association and Spectrum Access*

  * Joint user association(å¤šç”¨æˆ·å½’å±) and spectrum access problems æ˜¯å…¸å‹çš„éå‡¸ä¼˜åŒ–é—®é¢˜

  >ä»¥å‰é‡‡ç”¨äº†çº¿æ€§è§„åˆ’ç­‰ä¼ ç»Ÿæ–¹æ³•æ¥è·å¾—æœ€ä¼˜è§£ã€‚ä½†è¿™äº›æ–¹æ³•å‡ ä¹éœ€è¦çŸ¥é“å®Œæ•´å¹¶ä¸”å‡†ç¡®çš„ç½‘ç»œä¿¡æ¯ï¼Œè€Œè¿™é€šå¸¸æ— æ³•è¾¾åˆ°çš„ã€‚
  >
  >æ‰€ä»¥ä½¿ç”¨Q-learningç®—æ³•ã€‚ç„¶è€Œï¼Œç”±äºjoint optimization problemå­˜åœ¨è¾ƒå¤§çš„stateç©ºé—´å’Œactionç©ºé—´ï¼Œå› æ­¤è·å¾—æœ€ä¼˜è§£å…·æœ‰å¾ˆå¤§çš„æŒ‘æˆ˜æ€§
  >
  >æ‰€ä»¥ç”¨DQN

  ![Screenshot 2021-01-05 at 6.58.41 PM](/Users/yannie/Library/Application Support/typora-user-images/Screenshot 2021-01-05 at 6.58.41 PM.png)

  * åœ¨ä¸Šå›¾ä¸­ï¼Œæ¯ä¸ªç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼Œåœ¨ä¿è¯ç”¨æˆ·çš„ä¿¡å™ªæ¯”(SINR)é«˜äºæœ€ä½æœåŠ¡è´¨é‡(QoS)è¦æ±‚çš„åŒæ—¶ï¼Œé€‰æ‹©ä¸€ä¸ªBSå’Œä¸€ä¸ªchannelï¼Œä½¿å…¶æ•°æ®é€Ÿç‡æœ€å¤§åŒ–ã€‚
  * agentï¼šæ¯ä¸ªuser        stateï¼ša vector including QoS states of all users(ç”¨æˆ·çš„QoSçŠ¶æ€æ˜¯æŒ‡å…¶SINRæ˜¯å¦è¶…è¿‡æœ€å°QoSè¦æ±‚)
  * åœ¨æ¯ä¸ªslotä¸­ï¼Œç”¨æˆ·é‡‡å–ä¸€ä¸ªactionï¼Œå°±ä¼šå¾—åˆ°ä¸€ä¸ªnegative rewardæˆ–æ˜¯ positive reward, ç”±äºä¸€ä¸ªç”¨æˆ·çš„ç´¯è®¡å¥–åŠ±è¿˜å–å†³äºåˆ«çš„ç”¨æˆ·ï¼Œæ‰€ä»¥è¯¥é—®é¢˜å¯è¢«çœ‹ä½œMDP
  * ä¹Ÿæ˜¯ä½¿ç”¨DDQNå’ŒDueling DQNæ¥è§£å†³é—®é¢˜
  * å®éªŒè¡¨æ˜ï¼šDQNå¯ä»¥æœ‰æ•ˆåœ°ç”¨äºè§£å†³è¯¸å¦‚HetNetså’Œç‰©è”ç½‘ç­‰å¤§è§„æ¨¡ç³»ç»Ÿä¸­çš„è”åˆä¼˜åŒ–é—®é¢˜

  >HetNets: Heterogeneous network å¼‚è´¨ç½‘ç»œï¼šè¿™ä¸ªç³»ç»Ÿç”±ä¸åŒæ“ä½œç³»ç»Ÿç»„æˆã€‚

  ##### use the DQL for a joint user association, spectrum access, and content caching problem.

  >UAV: Unmanned aerial vehicle  æ— äººæœº

  * è¯¥ç½‘ç»œæ¨¡å‹æ˜¯ä¸€ä¸ªLTEç½‘ç»œï¼Œç”±ä¸ºåœ°é¢ç”¨æˆ·æœåŠ¡çš„UAVç»„æˆã€‚æ— äººæœºè£…å¤‡æœ‰å­˜å‚¨å•å…ƒï¼Œå¹¶å¯ä»¥ä½œä¸ºç¼“å­˜å¯ç”¨LTE-BSsã€‚æ— äººæœºå¯ä»¥è®¿é—®ç½‘ç»œä¸­çš„è®¸å¯æ³¢æ®µå’Œéè®¸å¯æ³¢æ®µã€‚æ— äººæœºç”±ä¸€ä¸ªåŸºäºäº‘çš„æœåŠ¡å™¨æ§åˆ¶ï¼Œä»äº‘åˆ°æ— äººæœºçš„ä¼ è¾“é€šè¿‡ä½¿ç”¨è®¸å¯çš„èœ‚çªé¢‘æ®µå®ç°ã€‚

  * UAVçš„è¦è§£å†³çš„é—®é¢˜ä¸ºï¼š1) æœ€ä¼˜ç”¨æˆ·å…³è”  2)è®¸å¯é¢‘å¸¦ä¸Šçš„å¸¦å®½åˆ†é…æŒ‡æ ‡  3ï¼‰æœªæˆæƒæ³¢æ®µçš„æ—¶æ®µæŒ‡æ ‡  4ï¼‰ç¡®å®ša set of popular contentï¼ˆç”¨æˆ·è¯·æ±‚å®ƒå¯ä»¥æœ€å¤§åŒ– **ç¨³å®šé˜Ÿåˆ—ä¸­ç”¨æˆ·çš„æ•°é‡** å³æ»¡è¶³å†…å®¹ä¼ è¾“å»¶è¿Ÿçš„ç”¨æˆ·æ•°é‡ï¼‰

  * æ— äººæœºçš„é—®é¢˜æ˜¯ç»„åˆçš„ï¼Œéå‡¸é—®é¢˜

  * æ— äººæœºä¸çŸ¥é“ç”¨æˆ·çš„è¯·æ±‚ï¼Œå› æ­¤ä½¿ç”¨ Liquid State Machine approach (LSM)æ¥é¢„æµ‹ç”¨æˆ·çš„å†…å®¹è¯·æ±‚åˆ†å¸ƒå¹¶è¿›è¡Œèµ„æºåˆ†å¸ƒ

  * UAVä½œä¸ºagentï¼Œä½¿ç”¨åŸºäºLSMçš„å­¦ä¹ ç®—æ³•æ¥å¯»æ‰¾æœ€ä¼˜users association

  * è¾“å…¥ï¼šactionï¼ˆother UAVs é‡‡å–çš„ UAV-user association schemesï¼‰ 

    è¾“å‡ºï¼šthe expected numbers of users with stable queues corresponding to actions that the UAV can take.

  * ç”¨æˆ·å…³è”å®Œæˆä¹‹åï¼Œæ ¹æ®[61]çš„ç»“æœç¡®å®šæœ€ä¼˜çš„å†…å®¹ç¼“å­˜ï¼Œå¹¶ä½¿ç”¨çº¿æ€§è§„åˆ’è¿›è¡Œæœ€ä¼˜é¢‘è°±åˆ†é…ã€‚åŸºäºGordonå®šç†[62]ï¼Œè¯æ˜äº†æ‰€æå‡ºçš„DQLä»¥æ¦‚ç‡1æ”¶æ•›

  * ç»“æœï¼šDQLå¯ä»¥åœ¨400æ¬¡è¿­ä»£å†…æ”¶æ•›ã€‚ä¸Q-learningç®—æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„DQNç®—æ³•çš„æ”¶æ•›æ—¶é—´æé«˜äº†33%ã€‚ä¸æ— ç¼“å­˜çš„Q-learningç›¸æ¯”ï¼Œæ‰€æå‡ºçš„DQLæ˜¾è‘—æé«˜äº†å…·æœ‰ç¨³å®šé˜Ÿåˆ—çš„ç”¨æˆ·æ•°é‡ï¼Œæœ€é«˜å¯è¾¾50%ã€‚äº‹å®ä¸Šï¼Œèƒ½æºæ•ˆç‡å¯¹æ— äººæœºä¹Ÿå¾ˆé‡è¦ï¼Œå› æ­¤å°†DQLåº”ç”¨äºè”åˆç”¨æˆ·å…³è”ã€é¢‘è°±æ¥å…¥å’ŒåŠŸç‡åˆ†é…é—®é¢˜éœ€è¦ç ”ç©¶ã€‚

  ###  *Adaptive Rate Control*

  * Video streamingç›®å‰ä¸»è¦çš„æ ‡å‡†æ˜¯:DASH(Dynamic Adaptive Streaming over HTTP)
  * DASHèƒ½å¤Ÿåˆ©ç”¨ç°æœ‰çš„å†…å®¹deliveryç½‘ç»œåŸºç¡€è®¾æ–½ï¼Œå¹¶ä¸å¤šç§å®¢æˆ·ç«¯åº”ç”¨ç¨‹åºå…¼å®¹ã€‚

  ![Screenshot 2021-01-06 at 9.12.43 AM](/Users/yannie/Library/Application Support/typora-user-images/Screenshot 2021-01-06 at 9.12.43 AM.png)

  * è§†é¢‘åœ¨æœåŠ¡å™¨ä¸Šå­˜å‚¨ä¸ºå¤šä¸ªæ®µï¼Œå³å—ã€‚æ¯ä¸ªç‰‡æ®µä»¥ä¸åŒçš„å‹ç¼©çº§åˆ«è¿›è¡Œç¼–ç ï¼Œä»¥ç”Ÿæˆå…·æœ‰ä¸åŒæ¯”ç‰¹ç‡çš„*representations* ï¼Œå³ä¸åŒçš„è§†é¢‘è§†è§‰è´¨é‡ã€‚

  * åœ¨æ¯ä¸€ä¸ªtime slotï¼Œå®¢æˆ·é€‰æ‹©ä¸€ä¸ªrepresentation(å³é‚£äº›å…·æœ‰ä¸€å®šæ¯”ç‰¹ç‡çš„æ®µ)å»ä¸‹è½½

  * clienté—®é¢˜æ˜¯: æ‰¾åˆ°ä¸€ä¸ªæœ€ä½³ç­–ç•¥æ¥æœ€å¤§åŒ–QoE(å³ï¼šæœ€å¤§åŒ–å¹³å‡æ¯”ç‰¹ç‡å’Œæœ€å°åŒ–rebufferingï¼Œå³è§†é¢‘æ’­æ”¾å†»ç»“çš„æ—¶é—´)

  * ä¸Šè¿°é—®é¢˜ä¹Ÿå¯ä»¥å»ºæ¨¡æˆä¸€ä¸ªMDP ï¼š    agent: client   action: é€‰æ‹©ä¸€ä¸ªrepresentationå»ä¸‹è½½

    rewardï¼šè¢«å®šä¹‰ä¸ºä¸€ä¸ªå‡½æ•°(å‚æ•°åŒ…æ‹¬: visual quality of the video / video quality stability / rebuffering event / buffer state )

    State: (i) the video quality of the last downloaded segment, (ii) the current buffer state, (iii) the rebuffering time. (iv) the channel capacities experienced during downloading of segments in the past time slots.(è¿‡å»æ‰€æœ‰æ—¶é—´)

  * MDPå¯ä»¥é€šè¿‡ä½¿ç”¨åŠ¨æ€è§„åˆ’æ¥è§£å†³ï¼Œä½†éšç€é—®é¢˜è§„æ¨¡çš„å¢åŠ ï¼Œè®¡ç®—å¤æ‚åº¦è¿…é€Ÿå˜å¾—éš¾ä»¥ç®¡ç†ã€‚æ‰€ä»¥ç”¨DQLï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯LSTM network(å¹¶åº”ç”¨äº†peephole).  è¾“å…¥:state. è¾“å‡º:Q-values corresponding to the clientâ€™s possible actions

  * ç»“æœï¼šè¯¥DQLç®—æ³•æ¯”Q-learningæ”¶æ•›é€Ÿåº¦æ›´å¿«ã€‚è¯¥ç®—æ³•èƒ½å¤Ÿæé«˜äº†è§†é¢‘è´¨é‡ï¼Œå‡å°‘äº†å»¶è¿Ÿï¼Œå› ä¸ºå…¶è€ƒè™‘ç¼“å†²åŒºçŠ¶æ€å’Œä¿¡é“å®¹é‡æ¥å¯¹ç¼“å†²åŒºè¿›è¡ŒåŠ¨æ€ç®¡ç†ã€‚

  #### A3C(Asynchronous Advantage Actor-Critic)çš„æ–¹æ³•æå‡ºå¢å¼ºå’ŒåŠ å¿«äº†è®­ç»ƒçš„é€Ÿåº¦

  * A3CåŒ…æ‹¬ä¸¤ä¸ªneural networkï¼ŒThe actor network is to choose bitrates for the client, and the critic network helps train the actor network
  * actorç½‘ç»œä¸­ï¼šè¾“å…¥: client's state  è¾“å‡º: policy(å³ï¼šclientå¯èƒ½é‡‡å–actionçš„æ¦‚ç‡åˆ†å¸ƒã€‚)   actionï¼šchoose the next representation
  * criticç½‘ç»œä¸­:  è¾“å…¥: client's state   è¾“å‡º: the expected total reward when following the policy obtained from the actor network
  * ç»“æœ: ä¸bitrate control schemeç›¸æ¯”ï¼Œæ‰€æå‡ºçš„DQLå¯ä»¥å°†å¹³å‡QoEæé«˜25%ã€‚æ­¤å¤–ï¼Œç”±äºæœ‰è¶³å¤Ÿçš„ç¼“å†²åŒºæ¥å¤„ç†ç½‘ç»œååé‡çš„æ³¢åŠ¨ï¼Œä¸baseline schemeç›¸æ¯”ï¼Œè¯¥DQLå‡å°‘äº†çº¦32.8%çš„rebufferingã€‚

  #### ç”±äºA3Cèƒ½å¤Ÿæ”¯æŒå¤šä¸ªagentå¹¶è¡Œè®­ç»ƒï¼Œæ‰€ä»¥DQLæ˜“éƒ¨ç½²åœ¨å¤šå®¢æˆ·ç«¯ç½‘ç»œä¸­

  * clientä½œä¸ºagentæ¥è§‚å¯Ÿrewardï¼Œå…¶å…ˆç»™serverå‘é€ä¸€ä¸ªtuple(state, action, and reward)
  * serverä½¿ç”¨actor-criticç®—æ³•æ¥æ›´æ–°å…¶actor network modelï¼Œç„¶åå°†è¿™ä¸ªæ–°çš„modelä¼ ç»™agent
  * è¿™ç§æ›´æ–°è¿‡ç¨‹å¯ä»¥åœ¨æ‰€æœ‰ä»£ç†ä¹‹é—´å¼‚æ­¥è¿›è¡Œï¼Œæé«˜äº†è®­ç»ƒçš„è´¨é‡å’Œé€Ÿåº¦ã€‚
  * è™½ç„¶å¹¶è¡Œè®­ç»ƒæ–¹æ¡ˆåœ¨å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¹‹é—´å¯èƒ½ä¼šäº§ç”Ÿä¸€ä¸ªå¾€è¿”æ—¶é—´(RTT)ï¼Œä½†[67]ä¸­çš„ä»¿çœŸç»“æœè¡¨æ˜ï¼Œå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ä¹‹é—´çš„å¾€è¿”æ—¶é—´(RTT)ä»…ä½¿å¹³å‡QoEé™ä½3.5%ã€‚å› æ­¤æ‰€æå‡ºçš„DQLå¯ä»¥åœ¨çœŸå®çš„ç½‘ç»œç³»ç»Ÿä¸­å®ç°ã€‚

  ##### prediction network

  * ä¸Šè¿°è¾“å…¥ä¸­çš„client stateåŒ…æ‹¬ï¼švideo quality of the last downloaded video segmentã€‚ç”±äºè¿™ä¸ªvideo segment is rawï¼Œå…¶å¯èƒ½å¯¼è‡´ â€œstate explosionâ€ã€‚ä¸ºäº†reduce the state space and to improve the QoEï¼Œæ‰€ä»¥æå‡ºäº† prediction network
  * é¢„æµ‹ç½‘ç»œä½¿ç”¨CNNå’ŒRNNä»åŸå§‹è§†é¢‘ç‰‡æ®µä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ã€‚ç„¶åï¼Œå°†é¢„æµ‹ç½‘ç»œçš„è¾“å‡ºä½œä¸ºDQLçš„è¾“å…¥ä¹‹ä¸€ã€‚
  * ç»“æœï¼šæœ¬æ–‡æå‡ºçš„DQLå¯ä»¥å°†å¹³å‡QoEæé«˜25%ã€‚æ­¤å¤–ï¼Œç”±äºDQLçš„çŠ¶æ€ç©ºé—´å°ï¼Œä½¿å¾—è§†é¢‘ä¼ è¾“çš„å¹³å‡å»¶è¿Ÿé™ä½äº†45%å·¦å³ã€‚è¿™æ„å‘³ç€åœ¨çŠ¶æ€ç©ºé—´è¾ƒå¤§çš„æƒ…å†µä¸‹ï¼Œåº”è¯¥ä½¿ç”¨CNNæ¥æé«˜ç”¨æˆ·çš„QoEå’Œæ”¶æ•›æ—¶é—´

  é™¤äº†DASHç³»ç»Ÿï¼ŒDQLè¿˜å¯ä»¥æœ‰æ•ˆçš„ç”¨äºHVFT(High Volume Flexible Time)çš„é€Ÿç‡æ§åˆ¶

  ![Screenshot 2021-01-06 at 10.26.27 AM](/Users/yannie/Library/Application Support/typora-user-images/Screenshot 2021-01-06 at 10.26.27 AM.png)

  >traffic: æµé‡

  * ç”±äºHVFTçš„åº”ç”¨å…·æœ‰è¾ƒå¤§çš„æµé‡ï¼Œå› æ­¤éœ€è¦è¿›è¡Œæµé‡è°ƒåº¦ï¼Œå¦‚æ•°æ®é€Ÿç‡æ§åˆ¶

  * è¿‡å»æ–¹æ³•ï¼šä¸ºæ¯ä¸ªæµé‡ç±»å‹åˆ†é…é™æ€ä¼˜å…ˆçº§ï¼Œç„¶ååŸºäºå…¶ä¼˜å…ˆçº§è¿›è¡Œæµé‡è°ƒåº¦ã€‚ä½†è¿™ç§æ–¹æ³•å¹¶ä¸ä¼šè¿›åŒ–ã€‚ä»è€Œé€‚åº”æ–°çš„traffic classesã€‚æ‰€ä»¥ä½¿ç”¨DQLæ¥æä¾› adaptive rate control mechanism

  * BSçš„é—®é¢˜: æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„ç­–ç•¥ï¼Œå³ç”¨æˆ·çš„æ•°æ®é€Ÿç‡ï¼Œä»¥æœ€å¤§é™åº¦åœ°å¢åŠ HVFTä¼ è¾“æµé‡ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°é™ä½ç°æœ‰æ•°æ®æµé‡çš„æ€§èƒ½é€€åŒ–ã€‚ å› æ­¤è¿™ä¸ªé—®é¢˜ä¹Ÿå¯ä»¥è¢«å»ºæ¨¡æˆMDPé—®é¢˜

  * Agent: BS   state: the  current network state and the useful features extracted from network states in the past time slots

    åœ¨ä¸€ä¸ªæ—¶éš™çš„stateåŒ…æ‹¬ï¼šcellâ€™s traffic load(å°åŒºåœ¨è¯¥æ—¶æ®µçš„æµé‡è´Ÿè½½)  æ€»çš„ç½‘ç»œè¿æ¥æ•° ç”µæ± è´¨é‡

    actionåŒ…æ‹¬ï¼ša combination of the traffic rate for the users

    rewardè¢«å®šä¹‰ä¸ºä¸€ä¸ªå‡½æ•°ï¼šå‚æ•°åŒ…æ‹¬ (i) the sum of HVFT traffic
    (ii) traffic loss to existing applications due to the presence of the HVFT traffic
    (iii) the amount of bytes served below desired minimum throughput. 

  * **DQL ä½¿ç”¨çš„ä¹Ÿæ˜¯ the actor and critic networks with LSTM **

  * ç»“æœï¼šé€šè¿‡ä½¿ç”¨å¢¨å°”æœ¬é‡‡é›†çš„çœŸå®ç½‘ç»œæ•°æ®ï¼Œä»¿çœŸç»“æœè¡¨æ˜ï¼Œä¸å¯å‘å¼æ§åˆ¶æ–¹æ¡ˆç›¸æ¯”ï¼Œæ‰€æå‡ºçš„DQLæ–¹æ¡ˆä½¿HVFTæµé‡å¢åŠ äº†2å€ã€‚å› æ­¤ï¼Œæ–‡ä¸­æå‡ºçš„DQLæœ‰æœ›åº”ç”¨äºäººå£å¢é•¿è¾ƒå¤§çš„å¤§å‹åŸå¸‚çš„ç°ä»£ç½‘ç»œã€‚

  #### DQL can be used for the rate control to achieve multiple objectives in complex communication systems.

  * åœ¨ç³»ç»Ÿä¸­ï¼Œå‘å°„æœºéœ€è¦é…ç½®å¤šä¸ªä¼ è¾“å‚æ•°ï¼Œå¦‚ç¬¦å·ç‡ã€ç¼–ç ç‡ç­‰ï¼Œä»¥å®ç°å¤šä¸ªå†²çªç›®æ ‡ï¼Œå¦‚ä½è¯¯ç ç‡ã€æé«˜ååé‡ã€åŠŸç‡å’Œé¢‘è°±æ•ˆç‡ç­‰ã€‚å¯ä»¥ä½¿ç”¨è‡ªé€‚åº”ç¼–ç å’Œè°ƒåˆ¶æ–¹æ¡ˆï¼Œä½†è¯¥æ–¹æ³•åªèƒ½å®ç°æœ‰é™çš„ç›®æ ‡ã€‚so use DQL
  * Agent: ç³»ç»Ÿä¸­çš„transmitter    Action: æ˜¯ä¸€ä¸²é›†åˆ,åŒ…æ‹¬(i) symbol rate, (ii) energy per symbol, (iii) modulation mode, (iv) number of bits per symbol  (v) encoding rate.
  * ç›®æ ‡æ˜¯æœ€å¤§åŒ–ç³»ç»Ÿæ€§èƒ½ã€‚reward: é€‚åˆåº¦å‡½æ•°çš„æ€§èƒ½å‚æ•°,åŒ…æ‹¬(i) BER estimated at the receiver, (ii) throughput, (iii) spec- tral efficiency, (iv) power consumption, (v) transmit power efficiency.
  * State: system performance, e.g. reward

  To achieve multiple objectives, the DQL is implemented by using a set of multiple neural networks in parallel. 

  * è¾“å…¥ï¼šDQLå½“å‰çŠ¶æ€å’Œä¿¡é“æ¡ä»¶    è¾“å‡ºï¼špredicted action  é‡‡ç”¨Levenberg-Marquardtåå‘ä¼ æ’­ç®—æ³•å¯¹ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒ
  * ç»“æœï¼šæ‰€æå‡ºçš„DQLå¯ä»¥è¾¾åˆ°æ¯”è¾ƒç†æƒ³çš„é€‚åˆåº¦è¯„åˆ†ï¼Œå³ä¸åŒç›®æ ‡çš„åŠ æƒå’Œã€‚ä¹Ÿæ˜¯ç©·ä¸¾æœç´¢æ–¹æ³•

  ### summary

  â€‹	DQLåœ¨åŠ¨æ€ç½‘ç»œè®¿é—®å’Œè‡ªé€‚åº”é€Ÿç‡æ§åˆ¶ä¸­çš„åº”ç”¨å¤§éƒ¨åˆ†éƒ½è¢«å»ºæ¨¡æˆMDPã€‚æ­¤å¤–ï¼Œç”¨äº IoT (ç‰©è”ç½‘)å’ŒDASH(Dynamic Adaptive Streaming over HTTP)ç³»ç»Ÿçš„DQLæ–¹æ³•æ¯”å…¶ä»–ç½‘ç»œå—åˆ°æ›´å¤šå…³æ³¨ã€‚

  â€‹	æœªæ¥çš„ç½‘ç»œï¼Œå¦‚5Gç½‘ç»œï¼Œæ¶‰åŠå¤šä¸ªç½‘ç»œå®ä½“ï¼Œå®ƒä»¬æœ‰å¤šä¸ªç›¸äº’å†²çªçš„ç›®æ ‡ï¼Œå¦‚ï¼šä¾›åº”å•†çš„æ”¶å…¥ä¸ç”¨æˆ·çš„æ•ˆç”¨æœ€å¤§åŒ–ã€‚è¿™å¯¹ä¼ ç»Ÿçš„èµ„æºç®¡ç†æœºåˆ¶æå‡ºäº†ä¸€äº›æŒ‘æˆ˜ï¼Œå€¼å¾—æ·±å…¥ç ”ç©¶ã€‚

  

  #### 2. DQNåœ¨ CACHING AND OFFLOADING å¸è½½å’Œç¼“å­˜ä¸Šçš„åº”ç”¨

  #### 3. DQNåœ¨NETWORK SECURITY AND CONNECTIVITY PRESERVATION ç½‘ç»œå®‰å…¨å’Œè¿æ¥ä¿å­˜ ä¸Šçš„åº”ç”¨

  #### 4. å…¶å®ƒå„ç§å„æ ·çš„é—®é¢˜ 

  * *Traffic Engineering and Routing*
  * *Resource Sharing and Scheduling*
  * *Power Control and Data Collection*
  * *Direction-of-Arrival (DoA) Estimation*
  * *Signal Detection*
  * *User Association and Load Balancing*
  * *User Localization*
  * *Access Device Detection*

  #### 5. CHALLENGES, OPEN ISSUES, AND FUTURE RESEARCH DIRECTIONS æŒ‘æˆ˜ã€å¼€æ”¾é—®é¢˜åŠæœªæ¥ç ”ç©¶æ–¹å‘

  

  

  

  

  

  

















